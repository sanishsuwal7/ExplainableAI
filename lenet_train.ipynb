{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d3e671d5-ea38-4d53-9b93-700e21998a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Normalize\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import torch.optim as optim\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (projected_gradient_descent)\n",
    "\n",
    "import quantus\n",
    "import captum\n",
    "from captum.attr import Saliency, IntegratedGradients, NoiseTunnel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9dac2627-71f4-446d-b520-60255275ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "06a50ea5-7a18-426c-83ef-e32f27116f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), Normalize(mean=0.3814, std=0.3994)])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./datasets', train=True, download = True, transform=transformer)\n",
    "test_dataset = datasets.FashionMNIST(root='./datasets', train=False, download = True, transform=transformer)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True) # num_workers=4,\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d3b8e827-f84d-46a5-bd31-1a0d4024e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for natural and adversarial LeNet Model \n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool_1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.conv_2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool_2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.fc_1 = torch.nn.Linear(256, 120)\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.fc_2 = torch.nn.Linear(120, 84)\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.fc_3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool_1(self.relu_1(self.conv_1(x)))\n",
    "        x = self.pool_2(self.relu_2(self.conv_2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.relu_3(self.fc_1(x))\n",
    "        x = self.relu_4(self.fc_2(x))\n",
    "        x = self.fc_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0300c511-9636-4993-bfad-07ccfd1055b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "learning_rate = 0.001\n",
    "epochs = 50 \n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d2635ead-8fbd-40b1-8b0c-61c975dc1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, device):\n",
    "    model.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "    targets = torch.LongTensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits = torch.cat([logits, model(x_batch)])\n",
    "            targets = torch.cat([targets, y_batch])\n",
    "    \n",
    "    return torch.nn.functional.softmax(logits, dim=1), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f4441d-ed90-4319-ad80-2f5c246f71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_normal(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b23adf41-6462-47e1-a7f3-6cb823ea3111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - test accuracy: 84.84% and CE loss 0.39\n",
      "Epoch 2/50 - test accuracy: 86.71% and CE loss 0.66\n",
      "Epoch 3/50 - test accuracy: 88.12% and CE loss 0.52\n",
      "Epoch 4/50 - test accuracy: 87.97% and CE loss 0.16\n",
      "Epoch 5/50 - test accuracy: 88.17% and CE loss 0.37\n",
      "Epoch 6/50 - test accuracy: 88.92% and CE loss 0.05\n",
      "Epoch 7/50 - test accuracy: 88.87% and CE loss 0.32\n",
      "Epoch 8/50 - test accuracy: 87.97% and CE loss 0.34\n",
      "Epoch 9/50 - test accuracy: 89.63% and CE loss 0.42\n",
      "Epoch 10/50 - test accuracy: 89.14% and CE loss 0.12\n",
      "Epoch 11/50 - test accuracy: 88.67% and CE loss 0.05\n",
      "Epoch 12/50 - test accuracy: 89.57% and CE loss 0.37\n",
      "Epoch 13/50 - test accuracy: 89.65% and CE loss 0.07\n",
      "Epoch 14/50 - test accuracy: 90.19% and CE loss 0.33\n",
      "Epoch 15/50 - test accuracy: 89.70% and CE loss 0.23\n",
      "Epoch 16/50 - test accuracy: 89.77% and CE loss 0.13\n",
      "Epoch 17/50 - test accuracy: 89.27% and CE loss 0.13\n",
      "Epoch 18/50 - test accuracy: 89.28% and CE loss 0.12\n",
      "Epoch 19/50 - test accuracy: 89.38% and CE loss 0.20\n",
      "Epoch 20/50 - test accuracy: 89.29% and CE loss 0.16\n",
      "Epoch 21/50 - test accuracy: 89.34% and CE loss 0.14\n",
      "Epoch 22/50 - test accuracy: 89.44% and CE loss 0.03\n",
      "Epoch 23/50 - test accuracy: 89.38% and CE loss 0.08\n",
      "Epoch 24/50 - test accuracy: 89.05% and CE loss 0.05\n",
      "Epoch 25/50 - test accuracy: 88.96% and CE loss 0.02\n",
      "Epoch 26/50 - test accuracy: 88.20% and CE loss 0.30\n",
      "Epoch 27/50 - test accuracy: 89.13% and CE loss 0.06\n",
      "Epoch 28/50 - test accuracy: 88.83% and CE loss 0.04\n",
      "Epoch 29/50 - test accuracy: 89.22% and CE loss 0.01\n",
      "Epoch 30/50 - test accuracy: 88.38% and CE loss 0.06\n",
      "Epoch 31/50 - test accuracy: 89.40% and CE loss 0.14\n",
      "Epoch 32/50 - test accuracy: 88.93% and CE loss 0.16\n",
      "Epoch 33/50 - test accuracy: 89.15% and CE loss 0.20\n",
      "Epoch 34/50 - test accuracy: 88.72% and CE loss 0.16\n",
      "Epoch 35/50 - test accuracy: 88.67% and CE loss 0.03\n",
      "Epoch 36/50 - test accuracy: 89.11% and CE loss 0.33\n",
      "Epoch 37/50 - test accuracy: 89.30% and CE loss 0.05\n",
      "Epoch 38/50 - test accuracy: 89.20% and CE loss 0.13\n",
      "Epoch 39/50 - test accuracy: 88.76% and CE loss 0.19\n",
      "Epoch 40/50 - test accuracy: 88.68% and CE loss 0.00\n",
      "Epoch 41/50 - test accuracy: 88.97% and CE loss 0.07\n",
      "Epoch 42/50 - test accuracy: 89.03% and CE loss 0.03\n",
      "Epoch 43/50 - test accuracy: 88.80% and CE loss 0.19\n",
      "Epoch 44/50 - test accuracy: 89.17% and CE loss 0.07\n",
      "Epoch 45/50 - test accuracy: 88.86% and CE loss 0.04\n",
      "Epoch 46/50 - test accuracy: 88.82% and CE loss 0.00\n",
      "Epoch 47/50 - test accuracy: 89.16% and CE loss 0.07\n",
      "Epoch 48/50 - test accuracy: 89.28% and CE loss 0.01\n",
      "Epoch 49/50 - test accuracy: 88.86% and CE loss 0.07\n",
      "Epoch 50/50 - test accuracy: 88.92% and CE loss 0.06\n"
     ]
    }
   ],
   "source": [
    "model_normal = train_normal(model = model.to(device), epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9a390518-d09b-4080-917b-f68390cf814f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 88.92%\n"
     ]
    }
   ],
   "source": [
    "# Model to GPU and eval mode.\n",
    "model_normal.to(device)\n",
    "model_normal.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_normal, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dfb78616-0351-444e-a330-3994eeeb0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: models\\lenet_fmnist.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"lenet_fmnist.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving the model: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_normal.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8598c-2f5e-43f5-b10b-3771f6e27755",
   "metadata": {},
   "source": [
    "# Train Adversarial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30ace2b9-b265-419a-bb89-41a1ee2c36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "learning_rate = 1e-4\n",
    "epochs = 40\n",
    "eps = [0.01,0.03,0.06,0.0,0.3,0.5]\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "946b73cd-df81-41b5-b26d-eb3fbdbff41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, device):\n",
    "    model.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "    targets = torch.LongTensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits = torch.cat([logits, model(x_batch)])\n",
    "            targets = torch.cat([targets, y_batch])\n",
    "    \n",
    "    return torch.nn.functional.softmax(logits, dim=1), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "337aad80-ffe6-4e28-86fb-8e5a5d0bde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv(model, epsilon, epochs):\n",
    "    model.train()\n",
    "    eps = epsilon\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            x_batch = projected_gradient_descent(model, x_batch, eps, eps/10, 40, np.inf)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "181b24a9-9bcc-4f9a-bc23-25d0daf64b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - test accuracy: 74.91% and CE loss 0.61\n",
      "Epoch 2/40 - test accuracy: 79.06% and CE loss 0.47\n",
      "Epoch 3/40 - test accuracy: 81.38% and CE loss 0.84\n",
      "Epoch 4/40 - test accuracy: 82.89% and CE loss 0.35\n",
      "Epoch 5/40 - test accuracy: 83.80% and CE loss 0.48\n",
      "Epoch 6/40 - test accuracy: 84.79% and CE loss 0.23\n",
      "Epoch 7/40 - test accuracy: 84.83% and CE loss 0.18\n",
      "Epoch 8/40 - test accuracy: 85.29% and CE loss 0.33\n",
      "Epoch 9/40 - test accuracy: 86.13% and CE loss 0.33\n",
      "Epoch 10/40 - test accuracy: 86.52% and CE loss 0.37\n",
      "Epoch 11/40 - test accuracy: 86.38% and CE loss 0.56\n",
      "Epoch 12/40 - test accuracy: 87.10% and CE loss 0.11\n",
      "Epoch 13/40 - test accuracy: 86.97% and CE loss 0.42\n",
      "Epoch 14/40 - test accuracy: 87.02% and CE loss 0.32\n",
      "Epoch 15/40 - test accuracy: 87.43% and CE loss 0.17\n",
      "Epoch 16/40 - test accuracy: 87.34% and CE loss 0.39\n",
      "Epoch 17/40 - test accuracy: 88.18% and CE loss 0.14\n",
      "Epoch 18/40 - test accuracy: 88.15% and CE loss 0.36\n",
      "Epoch 19/40 - test accuracy: 88.11% and CE loss 0.22\n",
      "Epoch 20/40 - test accuracy: 88.03% and CE loss 0.40\n",
      "Epoch 21/40 - test accuracy: 88.50% and CE loss 0.17\n",
      "Epoch 22/40 - test accuracy: 88.66% and CE loss 0.13\n",
      "Epoch 23/40 - test accuracy: 88.31% and CE loss 0.21\n",
      "Epoch 24/40 - test accuracy: 88.64% and CE loss 0.27\n",
      "Epoch 25/40 - test accuracy: 88.62% and CE loss 0.20\n",
      "Epoch 26/40 - test accuracy: 88.77% and CE loss 0.22\n",
      "Epoch 27/40 - test accuracy: 88.25% and CE loss 0.14\n",
      "Epoch 28/40 - test accuracy: 89.01% and CE loss 0.34\n",
      "Epoch 29/40 - test accuracy: 88.54% and CE loss 0.30\n",
      "Epoch 30/40 - test accuracy: 88.54% and CE loss 0.13\n",
      "Epoch 31/40 - test accuracy: 89.23% and CE loss 0.25\n",
      "Epoch 32/40 - test accuracy: 88.99% and CE loss 0.20\n",
      "Epoch 33/40 - test accuracy: 89.12% and CE loss 0.24\n",
      "Epoch 34/40 - test accuracy: 88.99% and CE loss 0.26\n",
      "Epoch 35/40 - test accuracy: 89.30% and CE loss 0.43\n",
      "Epoch 36/40 - test accuracy: 89.10% and CE loss 0.16\n",
      "Epoch 37/40 - test accuracy: 89.19% and CE loss 0.08\n",
      "Epoch 38/40 - test accuracy: 89.25% and CE loss 0.10\n",
      "Epoch 39/40 - test accuracy: 89.44% and CE loss 0.18\n",
      "Epoch 40/40 - test accuracy: 89.50% and CE loss 0.31\n"
     ]
    }
   ],
   "source": [
    "model_adversarial = train_adv(model=model.to(device),\n",
    "                    epsilon = eps[0], \n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c299b3fd-fe4e-4c30-a067-04d115c0ff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 89.50%\n"
     ]
    }
   ],
   "source": [
    "# Model to GPU and eval mode.\n",
    "model_adversarial.to(device)\n",
    "model_adversarial.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_adversarial, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "242782e1-bb3d-482d-a210-da7bd8c72858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: models\\lenet_fmnist_adv.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"lenet_fmnist_adv.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving the model: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_adversarial.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e7bd3-47fc-4805-a735-b322298bb70f",
   "metadata": {},
   "source": [
    "# L1 Unstructured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01d50e6a-d0e4-4636-93c0-7590c97fd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c8519ae-bd90-4ed8-a6e6-44ed9ec2a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total_parameters = 0\n",
    "    for layer, param in model.named_parameters():\n",
    "        total_parameters += torch.count_nonzero(param.data)\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0de43668-8df2-4e98-a60a-65075e346e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpruned LeNet-5 model has 44426 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "orig_params = count_params(model)\n",
    "print(f\"Unpruned LeNet-5 model has {orig_params} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9675d74a-6004-4d51-ab45-2cad1fc79e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.name: conv_1.weight & param.shape = torch.Size([6, 1, 5, 5])\n",
      "layer.name: conv_1.bias & param.shape = torch.Size([6])\n",
      "layer.name: conv_2.weight & param.shape = torch.Size([16, 6, 5, 5])\n",
      "layer.name: conv_2.bias & param.shape = torch.Size([16])\n",
      "layer.name: fc_1.weight & param.shape = torch.Size([120, 256])\n",
      "layer.name: fc_1.bias & param.shape = torch.Size([120])\n",
      "layer.name: fc_2.weight & param.shape = torch.Size([84, 120])\n",
      "layer.name: fc_2.bias & param.shape = torch.Size([84])\n",
      "layer.name: fc_3.weight & param.shape = torch.Size([10, 84])\n",
      "layer.name: fc_3.bias & param.shape = torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer, param in model.named_parameters():\n",
    "    print(f\"layer.name: {layer} & param.shape = {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ce0bd78-d3f2-4073-8cf3-3b67ebbf51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1.weight torch.Size([6, 1, 5, 5])\n",
      "conv_1.bias torch.Size([6])\n",
      "conv_2.weight torch.Size([16, 6, 5, 5])\n",
      "conv_2.bias torch.Size([16])\n",
      "fc_1.weight torch.Size([120, 256])\n",
      "fc_1.bias torch.Size([120])\n",
      "fc_2.weight torch.Size([84, 120])\n",
      "fc_2.bias torch.Size([84])\n",
      "fc_3.weight torch.Size([10, 84])\n",
      "fc_3.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer_name in model.state_dict().keys():\n",
    "    print(layer_name, model.state_dict()[layer_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62817fb0-ae9a-4b72-b30e-d24391a15b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv_1.weight', 'conv_1.bias', 'conv_2.weight', 'conv_2.bias', 'fc_1.weight', 'fc_1.bias', 'fc_2.weight', 'fc_2.bias', 'fc_3.weight', 'fc_3.bias'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbc2db25-820e-4ac1-a191-aec61ea7b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(model):\n",
    "    conv1_sparsity = torch.sum(model.conv_1.weight == 0) \n",
    "    conv2_sparsity = torch.sum(model.conv_2.weight == 0)\n",
    "    fc1_sparsity = torch.sum(model.fc_1.weight == 0) \n",
    "    fc2_sparsity = torch.sum(model.fc_2.weight == 0) \n",
    "    fc3_sparsity = torch.sum(model.fc_3.weight == 0) \n",
    "\n",
    "    num = conv1_sparsity + conv2_sparsity +fc1_sparsity + fc2_sparsity + fc3_sparsity\n",
    "    denom = model.conv_1.weight.nelement() + model.conv_2.weight.nelement() + model.fc_1.weight.nelement() + model.fc_2.weight.nelement() + model.fc_3.weight.nelement()\n",
    "\n",
    "    global_sparsity = num/denom * 100\n",
    "\n",
    "    return global_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e01bea03-3473-4b0e-8a10-4ced33719739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 global sparsity = 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"LeNet-5 global sparsity = {compute_sparsity(model):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9d72630-dc33-4254-861e-86c0073356c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "for name, module in model.named_modules():\n",
    "    # prune 20% of weights/connections in for all hidden layaers-\n",
    "    if isinstance(module, torch.nn.Linear) and name != 'fc_3':\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.2)\n",
    "    \n",
    "    # prune 10% of weights/connections for output layer-\n",
    "    elif isinstance(module, torch.nn.Linear) and name == 'fc_3':\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae21c25b-f53a-4b27-9183-49340f5eafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 global sparsity = 18.66%\n"
     ]
    }
   ],
   "source": [
    "print(f\"LeNet-5 global sparsity = {compute_sparsity(model):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c19c0414-472d-47f6-a999-e34936851ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned LeNet-5 model has 44426 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "new_params = count_params(model)\n",
    "print(f\"Pruned LeNet-5 model has {new_params} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b15377d-95a4-4bbc-9825-c301b4ebc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, device):\n",
    "    model.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "    targets = torch.LongTensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits = torch.cat([logits, model(x_batch)])\n",
    "            targets = torch.cat([targets, y_batch])\n",
    "    \n",
    "    return torch.nn.functional.softmax(logits, dim=1), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5d9f3de-7904-48f0-81c5-50827c467d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned(model, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model!\n",
    "        if epochs%10==0:\n",
    "            predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "            test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7710ab1-8314-4576-a6fa-1b5c341d5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - test accuracy: 84.31% and CE loss 0.44\n",
      "Epoch 2/50 - test accuracy: 85.19% and CE loss 0.10\n",
      "Epoch 3/50 - test accuracy: 87.83% and CE loss 0.22\n",
      "Epoch 4/50 - test accuracy: 88.51% and CE loss 0.21\n",
      "Epoch 5/50 - test accuracy: 88.55% and CE loss 0.26\n",
      "Epoch 6/50 - test accuracy: 88.11% and CE loss 0.33\n",
      "Epoch 7/50 - test accuracy: 88.60% and CE loss 0.16\n",
      "Epoch 8/50 - test accuracy: 89.35% and CE loss 0.15\n",
      "Epoch 9/50 - test accuracy: 88.93% and CE loss 0.14\n",
      "Epoch 10/50 - test accuracy: 89.30% and CE loss 0.29\n",
      "Epoch 11/50 - test accuracy: 89.28% and CE loss 0.42\n",
      "Epoch 12/50 - test accuracy: 89.80% and CE loss 0.11\n",
      "Epoch 13/50 - test accuracy: 89.84% and CE loss 0.32\n",
      "Epoch 14/50 - test accuracy: 89.71% and CE loss 0.22\n",
      "Epoch 15/50 - test accuracy: 89.47% and CE loss 0.19\n",
      "Epoch 16/50 - test accuracy: 89.32% and CE loss 0.22\n",
      "Epoch 17/50 - test accuracy: 89.91% and CE loss 0.21\n",
      "Epoch 18/50 - test accuracy: 89.57% and CE loss 0.16\n",
      "Epoch 19/50 - test accuracy: 89.66% and CE loss 0.10\n",
      "Epoch 20/50 - test accuracy: 89.65% and CE loss 0.12\n",
      "Epoch 21/50 - test accuracy: 88.79% and CE loss 0.06\n",
      "Epoch 22/50 - test accuracy: 89.31% and CE loss 0.16\n",
      "Epoch 23/50 - test accuracy: 89.29% and CE loss 0.17\n",
      "Epoch 24/50 - test accuracy: 88.95% and CE loss 0.07\n",
      "Epoch 25/50 - test accuracy: 89.40% and CE loss 0.01\n",
      "Epoch 26/50 - test accuracy: 89.19% and CE loss 0.11\n",
      "Epoch 27/50 - test accuracy: 88.87% and CE loss 0.10\n",
      "Epoch 28/50 - test accuracy: 89.38% and CE loss 0.11\n",
      "Epoch 29/50 - test accuracy: 88.96% and CE loss 0.09\n",
      "Epoch 30/50 - test accuracy: 89.07% and CE loss 0.28\n",
      "Epoch 31/50 - test accuracy: 88.90% and CE loss 0.16\n",
      "Epoch 32/50 - test accuracy: 88.90% and CE loss 0.05\n",
      "Epoch 33/50 - test accuracy: 88.89% and CE loss 0.14\n",
      "Epoch 34/50 - test accuracy: 89.22% and CE loss 0.09\n",
      "Epoch 35/50 - test accuracy: 89.17% and CE loss 0.05\n",
      "Epoch 36/50 - test accuracy: 89.17% and CE loss 0.02\n",
      "Epoch 37/50 - test accuracy: 89.06% and CE loss 0.12\n",
      "Epoch 38/50 - test accuracy: 88.79% and CE loss 0.05\n",
      "Epoch 39/50 - test accuracy: 89.12% and CE loss 0.10\n",
      "Epoch 40/50 - test accuracy: 88.60% and CE loss 0.03\n",
      "Epoch 41/50 - test accuracy: 89.30% and CE loss 0.12\n",
      "Epoch 42/50 - test accuracy: 88.83% and CE loss 0.06\n",
      "Epoch 43/50 - test accuracy: 88.84% and CE loss 0.05\n",
      "Epoch 44/50 - test accuracy: 88.80% and CE loss 0.11\n",
      "Epoch 45/50 - test accuracy: 89.25% and CE loss 0.02\n",
      "Epoch 46/50 - test accuracy: 88.76% and CE loss 0.13\n",
      "Epoch 47/50 - test accuracy: 88.54% and CE loss 0.06\n",
      "Epoch 48/50 - test accuracy: 88.56% and CE loss 0.01\n",
      "Epoch 49/50 - test accuracy: 89.07% and CE loss 0.16\n",
      "Epoch 50/50 - test accuracy: 88.80% and CE loss 0.01\n"
     ]
    }
   ],
   "source": [
    "model_l1_unstructured = train_pruned(model = model.to(device), epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "850b3f11-c9b3-4ab1-812a-2c93af1bae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 88.80%\n"
     ]
    }
   ],
   "source": [
    "# Model to GPU and eval mode.\n",
    "model_l1_unstructured.to(device)\n",
    "model_l1_unstructured.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_l1_unstructured, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85ef5f06-c6a5-4bda-ad7f-a295f5b7a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: models\\lenet_fmnist_l1_unstructured.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"lenet_fmnist_l1_unstructured.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving the model: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_l1_unstructured.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2479d-2790-4238-bc9f-9981a28506ab",
   "metadata": {},
   "source": [
    "# Global Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b4f450cb-5881-40aa-a66a-7f17e0e7bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fd39f6e7-9078-459a-af02-24468e018abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv_1, 'weight'),\n",
    "    (model.conv_2, 'weight'),\n",
    "    (model.fc_1, 'weight'),\n",
    "    (model.fc_2, 'weight'),\n",
    "    (model.fc_3, 'weight')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "77a9bf0b-b601-4762-a31f-3ee082038582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 global sparsity = 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"LeNet-5 global sparsity = {compute_sparsity(model):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5eeb667e-23e9-4c45-8ba3-62c67ff17bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_rates_global = [0.2, 0.3, 0.4, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7417665c-3550-4640-9e82-a17ae5b47cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, device):\n",
    "    model.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "    targets = torch.LongTensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in data:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits = torch.cat([logits, model(x_batch)])\n",
    "            targets = torch.cat([targets, y_batch])\n",
    "    \n",
    "    return torch.nn.functional.softmax(logits, dim=1), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "91c0b98f-8afd-43d9-a6b8-c9375e1c923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned(model, epochs):\n",
    "    for iter_prune_round in range(1):\n",
    "        print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
    "        \n",
    "        # Prune layer-wise in a structured manner-\n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method = prune.L1Unstructured,\n",
    "            amount = prune_rates_global[iter_prune_round]\n",
    "            \n",
    "        )\n",
    "    \n",
    "        # Print current global sparsity level-\n",
    "        print(f\"LeNet-5 global sparsity = {compute_sparsity(model):.2f}%\")\n",
    "        \n",
    "        \n",
    "        # Fine-training loop-\n",
    "        print(\"\\nFine-tuning pruned model to recover model's performance\\n\")\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for x_batch, y_batch in train_dataloader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(x_batch)\n",
    "                loss = criterion(logits, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            # Evaluate model!\n",
    "            if epochs%10==0:\n",
    "                predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "                test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "566ee877-d22b-4981-9d3a-e405708ea4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iterative Global pruning round = 1\n",
      "LeNet-5 global sparsity = 20.00%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "Epoch 1/20 - test accuracy: 83.74% and CE loss 0.51\n",
      "Epoch 2/20 - test accuracy: 85.77% and CE loss 0.40\n",
      "Epoch 3/20 - test accuracy: 87.77% and CE loss 0.27\n",
      "Epoch 4/20 - test accuracy: 88.26% and CE loss 0.20\n",
      "Epoch 5/20 - test accuracy: 88.08% and CE loss 0.23\n",
      "Epoch 6/20 - test accuracy: 88.52% and CE loss 0.15\n",
      "Epoch 7/20 - test accuracy: 89.16% and CE loss 0.24\n",
      "Epoch 8/20 - test accuracy: 88.82% and CE loss 0.26\n",
      "Epoch 9/20 - test accuracy: 89.18% and CE loss 0.12\n",
      "Epoch 10/20 - test accuracy: 89.03% and CE loss 0.33\n",
      "Epoch 11/20 - test accuracy: 88.93% and CE loss 0.22\n",
      "Epoch 12/20 - test accuracy: 88.85% and CE loss 0.07\n",
      "Epoch 13/20 - test accuracy: 89.17% and CE loss 0.16\n",
      "Epoch 14/20 - test accuracy: 89.19% and CE loss 0.25\n",
      "Epoch 15/20 - test accuracy: 88.07% and CE loss 0.39\n",
      "Epoch 16/20 - test accuracy: 89.51% and CE loss 0.13\n",
      "Epoch 17/20 - test accuracy: 89.16% and CE loss 0.14\n",
      "Epoch 18/20 - test accuracy: 89.31% and CE loss 0.10\n",
      "Epoch 19/20 - test accuracy: 89.33% and CE loss 0.12\n",
      "Epoch 20/20 - test accuracy: 88.91% and CE loss 0.05\n"
     ]
    }
   ],
   "source": [
    "model_global = train_pruned(model = model.to(device), epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "38ad19ac-7ef3-42c2-b7d4-895843021cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 88.91%\n"
     ]
    }
   ],
   "source": [
    "# Model to GPU and eval mode.\n",
    "model_global.to(device)\n",
    "model_global.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_global, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "02fea924-0b36-4494-9265-2b81cd07b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: models\\lenet_fmnist_global.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"lenet_fmnist_global.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving the model: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_global.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a08e3-58b9-45af-bf02-2fb3dabb3587",
   "metadata": {},
   "source": [
    "# Layered Structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "571adef9-1569-429b-90d4-d79df54e6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5798760a-fc3d-4b5a-bcd8-eb996daa11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned(model, epochs):\n",
    "    for iter_prune_round in range(1):\n",
    "        print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1}\")\n",
    "        \n",
    "        # Prune layer-wise in a structured manner-\n",
    "        prune.ln_structured(model.conv_1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.conv_2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.fc_1, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.fc_2, name = \"weight\", amount = 0.1, n = 2, dim = 0)\n",
    "        prune.ln_structured(model.fc_3, name = \"weight\", amount = 0, n = 2, dim = 0)\n",
    "        \n",
    "        # Print current global sparsity level-\n",
    "        print(f\"LeNet-5 global sparsity = {compute_sparsity(model):.2f}%\")\n",
    "        \n",
    "        \n",
    "        # Fine-training loop-\n",
    "        print(\"\\nFine-tuning pruned model to recover model's performance\\n\")\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for x_batch, y_batch in train_dataloader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(x_batch)\n",
    "                loss = criterion(logits, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "            # Evaluate model!\n",
    "            if epochs%10==0:\n",
    "                predictions, labels = evaluate_model(model, test_dataloader, device)\n",
    "                test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())\n",
    "                print(f\"Epoch {epoch+1}/{epochs} - test accuracy: {(100 * test_acc):.2f}% and CE loss {loss.item():.2f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e27aee46-d61c-47bd-a1f7-02be3005b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iterative Global pruning round = 1\n",
      "LeNet-5 global sparsity = 9.86%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "Epoch 1/20 - test accuracy: 81.73% and CE loss 0.48\n",
      "Epoch 2/20 - test accuracy: 82.79% and CE loss 0.66\n",
      "Epoch 3/20 - test accuracy: 83.19% and CE loss 1.02\n",
      "Epoch 4/20 - test accuracy: 84.54% and CE loss 0.50\n",
      "Epoch 5/20 - test accuracy: 84.17% and CE loss 0.12\n",
      "Epoch 6/20 - test accuracy: 83.47% and CE loss 0.24\n",
      "Epoch 7/20 - test accuracy: 84.20% and CE loss 0.28\n",
      "Epoch 8/20 - test accuracy: 85.24% and CE loss 0.40\n",
      "Epoch 9/20 - test accuracy: 84.44% and CE loss 0.48\n",
      "Epoch 10/20 - test accuracy: 78.24% and CE loss 0.55\n",
      "Epoch 11/20 - test accuracy: 84.52% and CE loss 0.58\n",
      "Epoch 12/20 - test accuracy: 84.65% and CE loss 0.40\n",
      "Epoch 13/20 - test accuracy: 82.91% and CE loss 0.36\n",
      "Epoch 14/20 - test accuracy: 85.28% and CE loss 0.26\n",
      "Epoch 15/20 - test accuracy: 85.06% and CE loss 0.49\n",
      "Epoch 16/20 - test accuracy: 84.94% and CE loss 0.53\n",
      "Epoch 17/20 - test accuracy: 85.62% and CE loss 0.54\n",
      "Epoch 18/20 - test accuracy: 83.83% and CE loss 0.22\n",
      "Epoch 19/20 - test accuracy: 82.56% and CE loss 0.27\n",
      "Epoch 20/20 - test accuracy: 82.36% and CE loss 0.19\n"
     ]
    }
   ],
   "source": [
    "model_layered_structured = train_pruned(model = model.to(device), epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "43293264-6cac-4143-af44-a180b12a9b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 82.36%\n"
     ]
    }
   ],
   "source": [
    "# Model to GPU and eval mode.\n",
    "model_layered_structured.to(device)\n",
    "model_layered_structured.eval()\n",
    "\n",
    "# Check test set performance.\n",
    "predictions, labels = evaluate_model(model_layered_structured, test_dataloader, device)\n",
    "test_acc = np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.cpu().numpy())        \n",
    "print(f\"Model test accuracy: {(100 * test_acc):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c77ea042-f1af-4a64-8b76-6c85e25cd659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: models\\lenet_fmnist_structured.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"lenet_fmnist_structured.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving the model: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_layered_structured.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1cee4-3021-4c2a-85ce-19699fff84d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
