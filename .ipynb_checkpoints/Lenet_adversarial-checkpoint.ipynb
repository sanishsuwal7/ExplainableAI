{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc59d288-cf81-485e-a9f3-29acdae31caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b4804b-8861-48b3-bfbd-4fe3e711221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=\"./datasets/\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root=\"./datasets/\", train=False, download = True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54116d70-7b84-48e0-9d3c-94aa162fddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img for img, _ in train_dataset], dim =0)\n",
    "mean = imgs.view(1, -1).mean(dim =1)\n",
    "std = imgs.view(1, -1).std(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fa9213-918e-44a5-8df4-b5915cfca70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fd299a-240d-4057-9fc4-4aee2b6db90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=\"./datasets\", train=True, download = False, transform = mnist_transforms)\n",
    "test_dataset = datasets.MNIST(root=\"./datasets\", train=False, download = False, transform = mnist_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e183cc-1d2f-4efa-bfc4-dcb99174d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset = train_dataset, lengths=[train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d603ba7-37d3-40c1-9be1-12e1db395733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 64, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = 64, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22bcc0b1-55e8-48ce-82ec-25c6735605ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNet5V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            #1\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
    "            \n",
    "            #2\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 5*5\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96482f1b-a925-4f4b-9f5d-818273eabae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsgm(image, epsilon,data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon* sign_data_grad\n",
    "    perturbed_data = torch.clamp(perturbed_image, 0,1)\n",
    "    return perturbed_data\n",
    "\n",
    "def denorm(batch, mean= mean, std = std):\n",
    "    if isinstance(mean, list):\n",
    "        mean = torch.tensor(mean).to(device)\n",
    "    if isinstance(std, list):\n",
    "        std = torch.tensor(std).to(device)\n",
    "\n",
    "    return batch * std.view(1, -1, 1,1) + mean.view(1, -1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ae74168-4e4f-4ecd-b1e6-b641d72140d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_lenet5v1 = LeNet5V1().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model_lenet5v1.parameters(), lr = 0.001)\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a70c08dd-c64e-46fd-ae5f-8effc4c7cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "EPOCHS = 12\n",
    "\n",
    "def train(model,device,  train_loader, epsilon):\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X.requires_grad = True\n",
    "        \n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "       \n",
    "        data_grad = X.grad.data\n",
    "        perturbed_data = fsgm(X, epsilon, data_grad)\n",
    "    \n",
    "        output = model(perturbed_data)\n",
    "    \n",
    "        loss_adv = loss_fn(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_adv.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "\n",
    "def test(model,device,  test_loader, epsilon):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X.requires_grad = True\n",
    "        \n",
    "        output = model(X)\n",
    "        \n",
    "        init_pred = output.max(1, keepdim=True)[1][0]\n",
    "\n",
    "        if init_pred.item() != y[0].item():\n",
    "            continue\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        data_grad = X.grad.data\n",
    "        \n",
    "        perturbed_data = fsgm(X, epsilon, data_grad)\n",
    "\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        final_pred = output.max(1, keepdim=True)[1][0]\n",
    "        if final_pred.item() == y[0].item():\n",
    "            correct += 1\n",
    "            if len(adv_examples) < 5 and epsilon == 0:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))\n",
    "        else:\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))\n",
    "    \n",
    "    final_acc = correct / float(len(test_loader))\n",
    "    print(f\"Epsilon: {epsilon}\\t Test Accuracy= {final_acc}\")\n",
    "    \n",
    "    return  final_acc, adv_examples\n",
    "                \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b5ef5438-ef1d-4327-bf71-f4dc65874542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\t Test Accuracy= 0.9044585987261147\n",
      "Epsilon: 0.05\t Test Accuracy= 0.9617834394904459\n",
      "Epsilon: 0.1\t Test Accuracy= 0.8980891719745223\n",
      "Epsilon: 0.15\t Test Accuracy= 0.8980891719745223\n",
      "Epsilon: 0.2\t Test Accuracy= 0.9171974522292994\n",
      "Epsilon: 0.25\t Test Accuracy= 0.910828025477707\n",
      "Epsilon: 0.3\t Test Accuracy= 0.8853503184713376\n"
     ]
    }
   ],
   "source": [
    "epsilons = [0, 0.05, 0.1, 0.15, 0.20, 0.25, 0.30]\n",
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model_lenet5v1\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train(model,device, train_loader, epsilon=0.1)\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model,device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a4dc2-5c21-419e-8a66-ea6dc4e31a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
