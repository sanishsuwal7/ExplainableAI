{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbb49e9-06b3-4d26-9428-906fb6f9abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2dbe4ac-cfec-4c2b-a6f8-4eabc14cea6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72ec693-9be9-4213-a402-84650bd715c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f222c738-3769-480f-866d-d6c638012cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root= './data', train = True, download=True)\n",
    "test_dataset =  torchvision.datasets.CIFAR10(root= './data', train = False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a4ae2c-7402-43d8-96fd-f4866f2de1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8956ad3-625a-47e5-a845-76caa2809480",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "cifar_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df36c9a0-f0d3-4f05-9c43-c13089900318",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root= './data', train = True, download=False, transform = cifar_transforms)\n",
    "test_dataset =  torchvision.datasets.CIFAR10(root= './data', train = False, download=False, transform = cifar_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d59ad77d-be5c-48d5-b459-0957c02bfbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000, 10000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset = train_dataset, lengths = [train_size, val_size])\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f1e47ba-95d3-4944-a56b-9c51ff58142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset =train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(dataset= test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset = val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac55692c-3be6-48a9-9c7b-9280110ce5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(VGG,self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def make_layers(cfg):\n",
    "    layers = []\n",
    "    in_channels =3\n",
    "    for out_channels in cfg:\n",
    "        if out_channels == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size = 2, stride =2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1)\n",
    "            layers += [conv2d, nn.ReLU(inplace = True)]\n",
    "            in_channels = out_channels\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "\n",
    "def vgg16():\n",
    "    return VGG(make_layers(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf301a95-e55e-4a0e-a291-d16be3efa1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "918d336b-60e2-4319-a09c-6c507e30bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "model = vgg16()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum = 0.9, weight_decay = 5e-4)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd2ad0c2-7939-4fc8-b6d2-b6c8f8d66093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total_params = 0\n",
    "    for layer_names, param in model.named_parameters():\n",
    "        total_params += torch.count_nonzero(param.data)\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8e8613c-1fcf-43f7-8c76-970a4ac93b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpruned VGG-16 model has 15240906 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "orig_params = count_params(model)\n",
    "print(f\"Unpruned VGG-16 model has {orig_params} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d318e64-0c48-4267-a5c9-761466bc9dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.name: features.0.weight & param.shape = torch.Size([64, 3, 3, 3])\n",
      "layer.name: features.0.bias & param.shape = torch.Size([64])\n",
      "layer.name: features.2.weight & param.shape = torch.Size([64, 64, 3, 3])\n",
      "layer.name: features.2.bias & param.shape = torch.Size([64])\n",
      "layer.name: features.5.weight & param.shape = torch.Size([128, 64, 3, 3])\n",
      "layer.name: features.5.bias & param.shape = torch.Size([128])\n",
      "layer.name: features.7.weight & param.shape = torch.Size([128, 128, 3, 3])\n",
      "layer.name: features.7.bias & param.shape = torch.Size([128])\n",
      "layer.name: features.10.weight & param.shape = torch.Size([256, 128, 3, 3])\n",
      "layer.name: features.10.bias & param.shape = torch.Size([256])\n",
      "layer.name: features.12.weight & param.shape = torch.Size([256, 256, 3, 3])\n",
      "layer.name: features.12.bias & param.shape = torch.Size([256])\n",
      "layer.name: features.14.weight & param.shape = torch.Size([256, 256, 3, 3])\n",
      "layer.name: features.14.bias & param.shape = torch.Size([256])\n",
      "layer.name: features.17.weight & param.shape = torch.Size([512, 256, 3, 3])\n",
      "layer.name: features.17.bias & param.shape = torch.Size([512])\n",
      "layer.name: features.19.weight & param.shape = torch.Size([512, 512, 3, 3])\n",
      "layer.name: features.19.bias & param.shape = torch.Size([512])\n",
      "layer.name: features.21.weight & param.shape = torch.Size([512, 512, 3, 3])\n",
      "layer.name: features.21.bias & param.shape = torch.Size([512])\n",
      "layer.name: features.24.weight & param.shape = torch.Size([512, 512, 3, 3])\n",
      "layer.name: features.24.bias & param.shape = torch.Size([512])\n",
      "layer.name: features.26.weight & param.shape = torch.Size([512, 512, 3, 3])\n",
      "layer.name: features.26.bias & param.shape = torch.Size([512])\n",
      "layer.name: features.28.weight & param.shape = torch.Size([512, 512, 3, 3])\n",
      "layer.name: features.28.bias & param.shape = torch.Size([512])\n",
      "layer.name: classifier.1.weight & param.shape = torch.Size([512, 512])\n",
      "layer.name: classifier.1.bias & param.shape = torch.Size([512])\n",
      "layer.name: classifier.4.weight & param.shape = torch.Size([512, 512])\n",
      "layer.name: classifier.4.bias & param.shape = torch.Size([512])\n",
      "layer.name: classifier.6.weight & param.shape = torch.Size([10, 512])\n",
      "layer.name: classifier.6.bias & param.shape = torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer, param in model.named_parameters():\n",
    "    print(f\"layer.name: {layer} & param.shape = {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36983344-2b2b-440e-8375-9838da596162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight torch.Size([64, 3, 3, 3])\n",
      "features.0.bias torch.Size([64])\n",
      "features.2.weight torch.Size([64, 64, 3, 3])\n",
      "features.2.bias torch.Size([64])\n",
      "features.5.weight torch.Size([128, 64, 3, 3])\n",
      "features.5.bias torch.Size([128])\n",
      "features.7.weight torch.Size([128, 128, 3, 3])\n",
      "features.7.bias torch.Size([128])\n",
      "features.10.weight torch.Size([256, 128, 3, 3])\n",
      "features.10.bias torch.Size([256])\n",
      "features.12.weight torch.Size([256, 256, 3, 3])\n",
      "features.12.bias torch.Size([256])\n",
      "features.14.weight torch.Size([256, 256, 3, 3])\n",
      "features.14.bias torch.Size([256])\n",
      "features.17.weight torch.Size([512, 256, 3, 3])\n",
      "features.17.bias torch.Size([512])\n",
      "features.19.weight torch.Size([512, 512, 3, 3])\n",
      "features.19.bias torch.Size([512])\n",
      "features.21.weight torch.Size([512, 512, 3, 3])\n",
      "features.21.bias torch.Size([512])\n",
      "features.24.weight torch.Size([512, 512, 3, 3])\n",
      "features.24.bias torch.Size([512])\n",
      "features.26.weight torch.Size([512, 512, 3, 3])\n",
      "features.26.bias torch.Size([512])\n",
      "features.28.weight torch.Size([512, 512, 3, 3])\n",
      "features.28.bias torch.Size([512])\n",
      "classifier.1.weight torch.Size([512, 512])\n",
      "classifier.1.bias torch.Size([512])\n",
      "classifier.4.weight torch.Size([512, 512])\n",
      "classifier.4.bias torch.Size([512])\n",
      "classifier.6.weight torch.Size([10, 512])\n",
      "classifier.6.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer_name in model.state_dict().keys():\n",
    "    print(layer_name, model.state_dict()[layer_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30a48364-b779-4319-a488-f9676045330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias', 'features.28.weight', 'features.28.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e554c471-f943-4079-a34a-3f909b3225c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(model):\n",
    "    conv1_sparsity = (torch.sum(model.features[0].weight == 0) / model.features[0].weight.nelement()) * 100\n",
    "    conv2_sparsity = (torch.sum(model.features[2].weight == 0) / model.features[2].weight.nelement()) * 100\n",
    "    conv3_sparsity = (torch.sum(model.features[5].weight == 0) / model.features[5].weight.nelement()) * 100\n",
    "    conv4_sparsity = (torch.sum(model.features[7].weight == 0) / model.features[7].weight.nelement()) * 100\n",
    "    conv5_sparsity = (torch.sum(model.features[10].weight == 0) / model.features[10].weight.nelement()) * 100\n",
    "    conv6_sparsity = (torch.sum(model.features[12].weight == 0) / model.features[12].weight.nelement()) * 100\n",
    "    conv7_sparsity = (torch.sum(model.features[14].weight == 0) / model.features[14].weight.nelement()) * 100\n",
    "    conv8_sparsity = (torch.sum(model.features[17].weight == 0) / model.features[17].weight.nelement()) * 100\n",
    "    conv9_sparsity = (torch.sum(model.features[19].weight == 0) / model.features[19].weight.nelement()) * 100\n",
    "    conv10_sparsity = (torch.sum(model.features[21].weight == 0) / model.features[21].weight.nelement()) * 100\n",
    "    conv11_sparsity = (torch.sum(model.features[24].weight == 0) / model.features[24].weight.nelement()) * 100\n",
    "    conv12_sparsity = (torch.sum(model.features[26].weight == 0) / model.features[26].weight.nelement()) * 100\n",
    "    conv13_sparsity = (torch.sum(model.features[28].weight == 0) / model.features[28].weight.nelement()) * 100\n",
    "    fc1_sparsity = (torch.sum(model.classifier[1].weight == 0) / model.classifier[1].weight.nelement()) * 100\n",
    "    fc2_sparsity = (torch.sum(model.classifier[4].weight == 0) / model.classifier[4].weight.nelement()) * 100\n",
    "    op_sparsity = (torch.sum(model.classifier[6].weight == 0) / model.classifier[6].weight.nelement()) * 100\n",
    "\n",
    "    num = torch.sum(model.features[0].weight == 0) + torch.sum(model.features[2].weight == 0) + torch.sum(model.features[5].weight == 0) + torch.sum(model.features[7].weight == 0) + torch.sum(model.features[10].weight == 0) + torch.sum(model.features[12].weight == 0) + torch.sum(model.features[14].weight == 0) + torch.sum(model.features[17].weight == 0) + torch.sum(model.features[19].weight == 0) + torch.sum(model.features[21].weight == 0)+ torch.sum(model.features[24].weight == 0) + torch.sum(model.features[26].weight == 0) + torch.sum(model.features[28].weight == 0) + torch.sum(model.classifier[1].weight == 0) + torch.sum(model.classifier[4].weight == 0) + torch.sum(model.classifier[6].weight == 0)\n",
    "    denom = model.features[0].weight.nelement() + model.features[2].weight.nelement() + model.features[5].weight.nelement() + model.features[7].weight.nelement() + model.features[10].weight.nelement() + model.features[12].weight.nelement() + model.features[14].weight.nelement() + model.features[17].weight.nelement() + model.features[19].weight.nelement() + model.features[21].weight.nelement() + model.features[24].weight.nelement() + model.features[26].weight.nelement() + model.features[28].weight.nelement() + model.classifier[1].weight.nelement() + model.classifier[4].weight.nelement() + model.classifier[6].weight.nelement()\n",
    "    global_sparsity = num/denom * 100\n",
    "    return global_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36d89bdf-4c80-4a53-87aa-c7714eb00afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-16 global sparsity = 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"VGG-16 global sparsity = {compute_sparsity(model):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6728a2eb-ed06-42b7-aee6-9d9d92e06654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "features Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "features.0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.1 ReLU(inplace=True)\n",
      "features.2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.3 ReLU(inplace=True)\n",
      "features.4 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.5 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.6 ReLU(inplace=True)\n",
      "features.7 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.8 ReLU(inplace=True)\n",
      "features.9 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.10 Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.11 ReLU(inplace=True)\n",
      "features.12 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.13 ReLU(inplace=True)\n",
      "features.14 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.15 ReLU(inplace=True)\n",
      "features.16 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.17 Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.18 ReLU(inplace=True)\n",
      "features.19 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.20 ReLU(inplace=True)\n",
      "features.21 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.22 ReLU(inplace=True)\n",
      "features.23 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "features.24 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.25 ReLU(inplace=True)\n",
      "features.26 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.27 ReLU(inplace=True)\n",
      "features.28 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "features.29 ReLU(inplace=True)\n",
      "features.30 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "classifier Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Dropout(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "classifier.0 Dropout(p=0.5, inplace=False)\n",
      "classifier.1 Linear(in_features=512, out_features=512, bias=True)\n",
      "classifier.2 ReLU(inplace=True)\n",
      "classifier.3 Dropout(p=0.5, inplace=False)\n",
      "classifier.4 Linear(in_features=512, out_features=512, bias=True)\n",
      "classifier.5 ReLU(inplace=True)\n",
      "classifier.6 Linear(in_features=512, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79a8641b-b040-421d-8fa7-43b1f14f1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "for name, module in model.named_modules():\n",
    "    # prune 20% of weights/connections in for all hidden layaers-\n",
    "    if isinstance(module, torch.nn.Linear) and name != 'classifier.6':\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.2)\n",
    "    \n",
    "    # prune 10% of weights/connections for output layer-\n",
    "    elif isinstance(module, torch.nn.Linear) and name == 'classifier.6':\n",
    "        prune.l1_unstructured(module = module, name = 'weight', amount = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51a84a79-d639-43ba-ba53-8202a1535d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-16 global sparsity = 1.25%\n"
     ]
    }
   ],
   "source": [
    "print(f\"VGG-16 global sparsity = {compute_sparsity(model):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d186f4de-17ba-46d5-afff-90728a146631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpruned VGG-16 model has 15240906 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "new_params = count_params(model)\n",
    "print(f\"Unpruned VGG-16 model has {new_params} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15a6c1b2-f6a2-43ec-b786-b3b988e1454e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251ec2fdbd334aeb995f2375e3badc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train loss:  2.12329| Train acc:  0.16485| Val loss:  1.92164| Val acc:  0.21387\n",
      "Epoch: 1| Train loss:  1.88344| Train acc:  0.24189| Val loss:  1.75705| Val acc:  0.28730\n",
      "Epoch: 2| Train loss:  1.69761| Train acc:  0.32361| Val loss:  1.62123| Val acc:  0.35977\n",
      "Epoch: 3| Train loss:  1.57004| Train acc:  0.38664| Val loss:  1.49766| Val acc:  0.44238\n",
      "Epoch: 4| Train loss:  1.41709| Train acc:  0.47229| Val loss:  1.27192| Val acc:  0.53809\n",
      "Epoch: 5| Train loss:  1.20250| Train acc:  0.57385| Val loss:  1.02846| Val acc:  0.63965\n",
      "Epoch: 6| Train loss:  1.06467| Train acc:  0.62943| Val loss:  1.04742| Val acc:  0.64395\n",
      "Epoch: 7| Train loss:  0.98891| Train acc:  0.66015| Val loss:  0.89172| Val acc:  0.69863\n",
      "Epoch: 8| Train loss:  0.88995| Train acc:  0.70130| Val loss:  1.01201| Val acc:  0.67246\n",
      "Epoch: 9| Train loss:  0.84054| Train acc:  0.72211| Val loss:  0.88594| Val acc:  0.69648\n",
      "Epoch: 10| Train loss:  0.77875| Train acc:  0.74454| Val loss:  0.76246| Val acc:  0.74395\n",
      "Epoch: 11| Train loss:  0.75173| Train acc:  0.75421| Val loss:  0.67072| Val acc:  0.78770\n",
      "Epoch: 12| Train loss:  0.69501| Train acc:  0.77455| Val loss:  0.62687| Val acc:  0.79492\n",
      "Epoch: 13| Train loss:  0.67993| Train acc:  0.78183| Val loss:  0.69138| Val acc:  0.77129\n",
      "Epoch: 14| Train loss:  0.65095| Train acc:  0.79148| Val loss:  0.68417| Val acc:  0.78477\n",
      "Epoch: 15| Train loss:  0.63680| Train acc:  0.79585| Val loss:  0.64904| Val acc:  0.78789\n",
      "Epoch: 16| Train loss:  0.60420| Train acc:  0.80796| Val loss:  0.60007| Val acc:  0.81270\n",
      "Epoch: 17| Train loss:  0.59794| Train acc:  0.81040| Val loss:  0.62377| Val acc:  0.80547\n",
      "Epoch: 18| Train loss:  0.56241| Train acc:  0.82305| Val loss:  0.59532| Val acc:  0.81152\n",
      "Epoch: 19| Train loss:  0.55923| Train acc:  0.82331| Val loss:  0.67147| Val acc:  0.79355\n",
      "Epoch: 20| Train loss:  0.53274| Train acc:  0.83088| Val loss:  0.53822| Val acc:  0.82109\n",
      "Epoch: 21| Train loss:  0.52797| Train acc:  0.83477| Val loss:  0.57154| Val acc:  0.81777\n",
      "Epoch: 22| Train loss:  0.51599| Train acc:  0.83780| Val loss:  0.54866| Val acc:  0.82617\n",
      "Epoch: 23| Train loss:  0.51358| Train acc:  0.83919| Val loss:  0.60116| Val acc:  0.81563\n",
      "Epoch: 24| Train loss:  0.49623| Train acc:  0.84186| Val loss:  0.57861| Val acc:  0.81719\n",
      "Epoch: 25| Train loss:  0.46938| Train acc:  0.85227| Val loss:  0.54726| Val acc:  0.82891\n",
      "Epoch: 26| Train loss:  0.45968| Train acc:  0.85472| Val loss:  0.57255| Val acc:  0.82324\n",
      "Epoch: 27| Train loss:  0.45212| Train acc:  0.85901| Val loss:  0.64320| Val acc:  0.79688\n",
      "Epoch: 28| Train loss:  0.47544| Train acc:  0.85109| Val loss:  0.56739| Val acc:  0.82500\n",
      "Epoch: 29| Train loss:  0.45919| Train acc:  0.85584| Val loss:  0.53007| Val acc:  0.82461\n",
      "Epoch: 30| Train loss:  0.44698| Train acc:  0.86063| Val loss:  0.50992| Val acc:  0.84004\n",
      "Epoch: 31| Train loss:  0.43266| Train acc:  0.86329| Val loss:  0.52687| Val acc:  0.82969\n",
      "Epoch: 32| Train loss:  0.44908| Train acc:  0.85849| Val loss:  0.56383| Val acc:  0.81563\n",
      "Epoch: 33| Train loss:  0.43269| Train acc:  0.86357| Val loss:  0.50653| Val acc:  0.83809\n",
      "Epoch: 34| Train loss:  0.43048| Train acc:  0.86584| Val loss:  0.49959| Val acc:  0.84551\n",
      "Epoch: 35| Train loss:  0.42875| Train acc:  0.86599| Val loss:  0.56152| Val acc:  0.83711\n",
      "Epoch: 36| Train loss:  0.41342| Train acc:  0.86944| Val loss:  0.49609| Val acc:  0.84961\n",
      "Epoch: 37| Train loss:  0.40994| Train acc:  0.87163| Val loss:  0.49492| Val acc:  0.84492\n",
      "Epoch: 38| Train loss:  0.40410| Train acc:  0.87353| Val loss:  0.46975| Val acc:  0.85352\n",
      "Epoch: 39| Train loss:  0.40694| Train acc:  0.87219| Val loss:  0.51844| Val acc:  0.84316\n",
      "Epoch: 40| Train loss:  0.39291| Train acc:  0.87709| Val loss:  0.46818| Val acc:  0.86035\n",
      "Epoch: 41| Train loss:  0.38478| Train acc:  0.87863| Val loss:  0.51904| Val acc:  0.84180\n",
      "Epoch: 42| Train loss:  0.39436| Train acc:  0.87788| Val loss:  0.49112| Val acc:  0.84746\n",
      "Epoch: 43| Train loss:  0.39094| Train acc:  0.87772| Val loss:  0.48360| Val acc:  0.85059\n",
      "Epoch: 44| Train loss:  0.39950| Train acc:  0.87496| Val loss:  0.56459| Val acc:  0.82539\n",
      "Epoch: 45| Train loss:  0.39334| Train acc:  0.87629| Val loss:  0.45297| Val acc:  0.86113\n",
      "Epoch: 46| Train loss:  0.38087| Train acc:  0.88034| Val loss:  0.55001| Val acc:  0.83965\n",
      "Epoch: 47| Train loss:  0.38468| Train acc:  0.87964| Val loss:  0.47652| Val acc:  0.85098\n",
      "Epoch: 48| Train loss:  0.38251| Train acc:  0.88091| Val loss:  0.45106| Val acc:  0.85684\n",
      "Epoch: 49| Train loss:  0.36326| Train acc:  0.88562| Val loss:  0.42433| Val acc:  0.86836\n",
      "Epoch: 50| Train loss:  0.37071| Train acc:  0.88442| Val loss:  0.47858| Val acc:  0.85078\n",
      "Epoch: 51| Train loss:  0.37472| Train acc:  0.88107| Val loss:  0.50678| Val acc:  0.84766\n",
      "Epoch: 52| Train loss:  0.37060| Train acc:  0.88533| Val loss:  0.53591| Val acc:  0.84590\n",
      "Epoch: 53| Train loss:  0.37405| Train acc:  0.88446| Val loss:  0.45428| Val acc:  0.86191\n",
      "Epoch: 54| Train loss:  0.36741| Train acc:  0.88437| Val loss:  0.45966| Val acc:  0.84922\n",
      "Epoch: 55| Train loss:  0.35853| Train acc:  0.88932| Val loss:  0.45469| Val acc:  0.85566\n",
      "Epoch: 56| Train loss:  0.35179| Train acc:  0.89080| Val loss:  0.45012| Val acc:  0.85742\n",
      "Epoch: 57| Train loss:  0.35888| Train acc:  0.88814| Val loss:  0.45660| Val acc:  0.85879\n",
      "Epoch: 58| Train loss:  0.35199| Train acc:  0.89030| Val loss:  0.55888| Val acc:  0.82832\n",
      "Epoch: 59| Train loss:  0.36553| Train acc:  0.88676| Val loss:  0.45370| Val acc:  0.85879\n",
      "Epoch: 60| Train loss:  0.36220| Train acc:  0.88797| Val loss:  0.50134| Val acc:  0.85020\n",
      "Epoch: 61| Train loss:  0.35290| Train acc:  0.88926| Val loss:  0.46968| Val acc:  0.85762\n",
      "Epoch: 62| Train loss:  0.34247| Train acc:  0.89162| Val loss:  0.50245| Val acc:  0.84980\n",
      "Epoch: 63| Train loss:  0.35542| Train acc:  0.88850| Val loss:  0.50937| Val acc:  0.85059\n",
      "Epoch: 64| Train loss:  0.36067| Train acc:  0.88631| Val loss:  0.48547| Val acc:  0.85059\n",
      "Epoch: 65| Train loss:  0.34438| Train acc:  0.89226| Val loss:  0.49907| Val acc:  0.84688\n",
      "Epoch: 66| Train loss:  0.34848| Train acc:  0.89205| Val loss:  0.48777| Val acc:  0.84297\n",
      "Epoch: 67| Train loss:  0.34389| Train acc:  0.89364| Val loss:  0.50653| Val acc:  0.85352\n",
      "Epoch: 68| Train loss:  0.33527| Train acc:  0.89498| Val loss:  0.47750| Val acc:  0.85410\n",
      "Epoch: 69| Train loss:  0.34626| Train acc:  0.89185| Val loss:  0.43202| Val acc:  0.86660\n",
      "Epoch: 70| Train loss:  0.33492| Train acc:  0.89501| Val loss:  0.50672| Val acc:  0.83770\n",
      "Epoch: 71| Train loss:  0.34681| Train acc:  0.89146| Val loss:  0.50541| Val acc:  0.84824\n",
      "Epoch: 72| Train loss:  0.34819| Train acc:  0.89143| Val loss:  0.47989| Val acc:  0.85918\n",
      "Epoch: 73| Train loss:  0.32953| Train acc:  0.89684| Val loss:  0.52865| Val acc:  0.83691\n",
      "Epoch: 74| Train loss:  0.34619| Train acc:  0.89329| Val loss:  0.52440| Val acc:  0.84902\n",
      "Epoch: 75| Train loss:  0.34717| Train acc:  0.89202| Val loss:  0.54658| Val acc:  0.84453\n",
      "Epoch: 76| Train loss:  0.34012| Train acc:  0.89434| Val loss:  0.46127| Val acc:  0.85117\n",
      "Epoch: 77| Train loss:  0.33542| Train acc:  0.89532| Val loss:  0.49180| Val acc:  0.85605\n",
      "Epoch: 78| Train loss:  0.33922| Train acc:  0.89338| Val loss:  0.51203| Val acc:  0.83691\n",
      "Epoch: 79| Train loss:  0.33619| Train acc:  0.89530| Val loss:  0.45214| Val acc:  0.86387\n",
      "Epoch: 80| Train loss:  0.32793| Train acc:  0.89913| Val loss:  0.44099| Val acc:  0.86406\n",
      "Epoch: 81| Train loss:  0.32711| Train acc:  0.89973| Val loss:  0.42749| Val acc:  0.87090\n",
      "Epoch: 82| Train loss:  0.32814| Train acc:  0.89699| Val loss:  0.46345| Val acc:  0.85449\n",
      "Epoch: 83| Train loss:  0.32831| Train acc:  0.89793| Val loss:  0.41976| Val acc:  0.86133\n",
      "Epoch: 84| Train loss:  0.34177| Train acc:  0.89470| Val loss:  0.44169| Val acc:  0.86445\n",
      "Epoch: 85| Train loss:  0.32941| Train acc:  0.89818| Val loss:  0.55829| Val acc:  0.82617\n",
      "Epoch: 86| Train loss:  0.32577| Train acc:  0.89638| Val loss:  0.42208| Val acc:  0.87012\n",
      "Epoch: 87| Train loss:  0.33755| Train acc:  0.89562| Val loss:  0.46452| Val acc:  0.86074\n",
      "Epoch: 88| Train loss:  0.33195| Train acc:  0.89802| Val loss:  0.59131| Val acc:  0.83379\n",
      "Epoch: 89| Train loss:  0.33617| Train acc:  0.89426| Val loss:  0.45143| Val acc:  0.86133\n",
      "Epoch: 90| Train loss:  0.32121| Train acc:  0.89898| Val loss:  0.40624| Val acc:  0.87305\n",
      "Epoch: 91| Train loss:  0.31572| Train acc:  0.90098| Val loss:  0.46227| Val acc:  0.85664\n",
      "Epoch: 92| Train loss:  0.32452| Train acc:  0.89891| Val loss:  0.46151| Val acc:  0.86484\n",
      "Epoch: 93| Train loss:  0.33195| Train acc:  0.89643| Val loss:  0.46107| Val acc:  0.86270\n",
      "Epoch: 94| Train loss:  0.32319| Train acc:  0.89918| Val loss:  0.45589| Val acc:  0.86113\n",
      "Epoch: 95| Train loss:  0.31712| Train acc:  0.90005| Val loss:  0.43975| Val acc:  0.86602\n",
      "Epoch: 96| Train loss:  0.30603| Train acc:  0.90482| Val loss:  0.44903| Val acc:  0.86484\n",
      "Epoch: 97| Train loss:  0.32352| Train acc:  0.89932| Val loss:  0.40481| Val acc:  0.87227\n",
      "Epoch: 98| Train loss:  0.32533| Train acc:  0.89822| Val loss:  0.48537| Val acc:  0.85020\n",
      "Epoch: 99| Train loss:  0.31605| Train acc:  0.90091| Val loss:  0.42753| Val acc:  0.86699\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "from tqdm.notebook import tqdm\n",
    "# torch.cuda.empty_cache()\n",
    "# device-agnostic setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "accuracy = accuracy.to(device)\n",
    "model = model.to(device)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "        # torch.cuda.empty_cache()\n",
    "        # Training loop\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            acc = accuracy(y_pred, y)\n",
    "            train_acc += acc\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "            \n",
    "        # Validation loop\n",
    "        val_loss, val_acc = 0.0, 0.0\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in val_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                \n",
    "                y_pred = model(X)\n",
    "                \n",
    "                loss = loss_fn(y_pred, y)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                acc = accuracy(y_pred, y)\n",
    "                val_acc += acc\n",
    "                \n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_acc /= len(val_dataloader)\n",
    "        \n",
    "        print(f\"Epoch: {epoch}| Train loss: {train_loss: .5f}| Train acc: {train_acc: .5f}| Val loss: {val_loss: .5f}| Val acc: {val_acc: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be399e8-3292-4513-9eaa-a0959b0b4001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
